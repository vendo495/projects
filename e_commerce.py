# -*- coding: utf-8 -*-
"""E_commerce.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XYD86kePhWR0KVZ9QljFPoPX7XRQ6_FK
"""

import pandas as pd

# Load the training dataset
train_data = pd.read_csv('/content/train_data.csv')

# Display the first few rows of the dataset
train_data.head()

# Extract one review from each sentiment class
positive_review = train_data[train_data['sentiment'] == 'Positive']['reviews.text'].iloc[0]
negative_review = train_data[train_data['sentiment'] == 'Negative']['reviews.text'].iloc[0]
neutral_review = train_data[train_data['sentiment'] == 'Neutral']['reviews.text'].iloc[0]

positive_review, negative_review, neutral_review

# Check the class count for each sentiment
class_counts = train_data['sentiment'].value_counts()

class_counts

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize a Tf-Idf vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')

# Fit and transform the reviews.text column
X_tfidf = tfidf_vectorizer.fit_transform(train_data['reviews.text'])

X_tfidf.shape

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

# Initialize and train the Multinomial Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_tfidf, train_data['sentiment'])

# Predict on the training data
train_predictions = clf.predict(X_tfidf)

# Evaluate the classifier's performance
report = classification_report(train_data['sentiment'], train_predictions, target_names=['Negative', 'Neutral', 'Positive'])

report

"""# class imbalance

"""

from sklearn.utils import resample

# Separate each sentiment class
positive_data = train_data[train_data['sentiment'] == 'Positive']
neutral_data = train_data[train_data['sentiment'] == 'Neutral']
negative_data = train_data[train_data['sentiment'] == 'Negative']

# Oversample the minority classes
neutral_oversampled = resample(neutral_data, replace=True, n_samples=len(positive_data), random_state=42)
negative_oversampled = resample(negative_data, replace=True, n_samples=len(positive_data), random_state=42)

# Combine the oversampled minority classes with the majority class
oversampled_data = pd.concat([positive_data, neutral_oversampled, negative_oversampled])

# Convert reviews to Tf-Idf scores again
X_oversampled_tfidf = tfidf_vectorizer.transform(oversampled_data['reviews.text'])
y_oversampled = oversampled_data['sentiment']

# Check the new class distribution after manual oversampling
y_oversampled.value_counts()

# Train the Multinomial Naive Bayes classifier on the oversampled data
clf.fit(X_oversampled_tfidf, y_oversampled)

# Predict on the oversampled data
oversampled_predictions = clf.predict(X_oversampled_tfidf)

# Evaluate the classifier's performance on the oversampled data
oversampled_report = classification_report(y_oversampled, oversampled_predictions, target_names=['Negative', 'Neutral', 'Positive'])

oversampled_report

from sklearn.ensemble import RandomForestClassifier

# Initialize and train the Random Forest classifier
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_oversampled_tfidf, y_oversampled)

# Predict on the oversampled data
rf_predictions = rf_clf.predict(X_oversampled_tfidf)

# Evaluate the classifier's performance on the oversampled data
rf_report = classification_report(y_oversampled, rf_predictions, target_names=['Negative', 'Neutral', 'Positive'])

rf_report

from sklearn.ensemble import GradientBoostingClassifier

# Initialize and train the Gradient Boosting Classifier
gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_clf.fit(X_reduced_oversampled_tfidf, y_reduced_oversampled)

# Predict on the subset of the oversampled data
gb_predictions = gb_clf.predict(X_reduced_oversampled_tfidf)

# Evaluate the classifier's performance on the subset of the oversampled data
gb_report = classification_report(y_reduced_oversampled, gb_predictions, target_names=['Negative', 'Neutral', 'Positive'])

gb_report

from sklearn.svm import SVC

# Initialize and train the multi-class SVM
svm_clf = SVC(kernel='linear', decision_function_shape='ovr', random_state=42)
svm_clf.fit(X_reduced_oversampled_tfidf, y_reduced_oversampled)

# Predict on the subset of the oversampled data
svm_predictions = svm_clf.predict(X_reduced_oversampled_tfidf)

# Evaluate the classifier's performance on the subset of the oversampled data
svm_report = classification_report(y_reduced_oversampled, svm_predictions, target_names=['Negative', 'Neutral', 'Positive'])

svm_report

from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
from sklearn.metrics import classification_report

# Separate each sentiment class
positive_data = train_data[train_data['sentiment'] == 'Positive']
neutral_data = train_data[train_data['sentiment'] == 'Neutral']
negative_data = train_data[train_data['sentiment'] == 'Negative']

# Oversample the minority classes
neutral_oversampled = resample(neutral_data, replace=True, n_samples=len(positive_data), random_state=42)
negative_oversampled = resample(negative_data, replace=True, n_samples=len(positive_data), random_state=42)

# Combine the oversampled minority classes with the majority class
oversampled_data = pd.concat([positive_data, neutral_oversampled, negative_oversampled])

# Reduce the feature space using fewer Tf-Idf features
reduced_tfidf_vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')
X_reduced_tfidf = reduced_tfidf_vectorizer.fit_transform(oversampled_data['reviews.text'])
y_reduced = oversampled_data['sentiment']

# Split the data into training and holdout sets
X_train_blend, X_holdout_blend, y_train_blend, y_holdout_blend = train_test_split(
    X_reduced_tfidf, y_reduced, test_size=0.2, random_state=42)

# Train base models on the training set
rf_clf_blend = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf_blend.fit(X_train_blend, y_train_blend)

mnb_clf_blend = MultinomialNB()
mnb_clf_blend.fit(X_train_blend, y_train_blend)

# trained models to make predicted probabilities on the holdout set
rf_probabilities_blend = rf_clf_blend.predict_proba(X_holdout_blend)
mnb_probabilities_blend = mnb_clf_blend.predict_proba(X_holdout_blend)

# Stack probabilities to be used as features for the meta-model
stacked_probabilities = np.column_stack((rf_probabilities_blend, mnb_probabilities_blend))

# Train the meta-model (Logistic Regression) on the stacked probabilities
meta_model = LogisticRegression(max_iter=1000, random_state=42)
meta_model.fit(stacked_probabilities, y_holdout_blend)

# Predict on the holdout set using the meta-model
meta_predictions = meta_model.predict(stacked_probabilities)

# Evaluate the blending ensemble's performance
blending_report = classification_report(y_holdout_blend, meta_predictions, target_names=['Negative', 'Neutral', 'Positive'])
print(blending_report)

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

# Set parameters for tokenization and sequence padding
top_words = 5000
max_review_length = 100

# Tokenize the text data
tokenizer = Tokenizer(num_words=top_words, filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n', lower=True)
tokenizer.fit_on_texts(oversampled_data['reviews.text'])
X_sequences = tokenizer.texts_to_sequences(oversampled_data['reviews.text'])

# Pad sequences to ensure consistent length
X_padded = pad_sequences(X_sequences, maxlen=max_review_length)

# Convert sentiment labels to one-hot encoded format
sentiment_mapping = {'Negative': 0, 'Neutral': 1, 'Positive': 2}
y_encoded = to_categorical(oversampled_data['sentiment'].map(sentiment_mapping))

from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dense, Dropout

# Define the LSTM model
embedding_length = 32

model_lstm = Sequential()
model_lstm.add(Embedding(top_words, embedding_length, input_length=max_review_length))
model_lstm.add(LSTM(100))
model_lstm.add(Dropout(0.5))
model_lstm.add(Dense(3, activation='softmax'))
model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model_lstm.summary()

# Train the model
model_lstm.fit(X_padded, y_encoded, epochs=10, batch_size=64, validation_split=0.2)

from keras.layers import GRU

# Define the GRU model
model_gru = Sequential()
model_gru.add(Embedding(top_words, embedding_length, input_length=max_review_length))
model_gru.add(GRU(100))
model_gru.add(Dropout(0.5))
model_gru.add(Dense(3, activation='softmax'))
model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model_gru.summary()

# Train the model
model_gru.fit(X_padded, y_encoded, epochs=10, batch_size=64, validation_split=0.2)

from sklearn.decomposition import LatentDirichletAllocation

# Number of topics
n_topics = 5

# Create and fit the LDA model
lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
lda_result = lda.fit_transform(X_reduced_tfidf)

# Display the top words for each topic
def display_topics(model, feature_names, no_top_words):
    topic_dict = {}
    for topic_idx, topic in enumerate(model.components_):
        top_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]
        topic_dict["Topic %d" % (topic_idx)] = top_words
    return topic_dict

no_top_words = 10
lda_topics = display_topics(lda, reduced_tfidf_vectorizer.get_feature_names_out(), no_top_words)
lda_topics

from sklearn.cluster import KMeans

# Choose a number of clusters; we'll start with 5 to match our previous number of topics
n_clusters = 5

# Apply KMeans clustering
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
clusters = kmeans.fit_predict(X_reduced_tfidf)

# Function to get top keywords for each cluster
def get_top_keywords(data, clusters, labels, n_terms):
    df = pd.DataFrame(data.todense()).groupby(clusters).mean()

    top_keywords = {}
    for i, r in df.iterrows():
        top_keywords["Cluster %d" % i] = [labels[t] for t in np.argsort(r)[-n_terms:]]

    return top_keywords

cluster_keywords = get_top_keywords(X_reduced_tfidf, clusters, reduced_tfidf_vectorizer.get_feature_names_out(), 10)
cluster_keywords

# Increase the number of topics for a more granular exploration
n_topics_detailed = 10

# Create and fit the LDA model
lda_detailed = LatentDirichletAllocation(n_components=n_topics_detailed, random_state=42, max_iter=15)
lda_result_detailed = lda_detailed.fit_transform(X_reduced_tfidf)

# Display the top words for each topic
no_top_words_detailed = 15
lda_topics_detailed = display_topics(lda_detailed, reduced_tfidf_vectorizer.get_feature_names_out(), no_top_words_detailed)
lda_topics_detailed

